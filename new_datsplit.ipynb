{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea4ed23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83274d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËØªÂèñÊï∞ÊçÆ\n",
    "train_csv_path = r\"C:\\Users\\Vivo\\2025_medicalimage_and_AI\\MURA-v1.1\\train_labeled_studies.csv\"\n",
    "valid_csv_path = r\"C:\\Users\\Vivo\\2025_medicalimage_and_AI\\MURA-v1.1\\valid_labeled_studies.csv\"\n",
    "data_root = r\"C:\\Users\\Vivo\\2025_medicalimage_and_AI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76bf6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1)\n",
    "])\n",
    "\n",
    "# Ëé∑ÂèñÁóÖ‰∫∫ÁªüËÆ°‰ø°ÊÅØÁöÑÂáΩÊï∞\n",
    "def get_patient_stats(csv_path, mode):\n",
    "    df = pd.read_csv(csv_path, header=None, names=['path', 'label'])\n",
    "    stats = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        study_rel_path, label = row['path'], row['label']\n",
    "        study_path = os.path.join(data_root, study_rel_path)\n",
    "        image_paths = glob(os.path.join(study_path, \"*.png\"))\n",
    "\n",
    "        pixel_means = []\n",
    "        pixel_stds = []\n",
    "\n",
    "        for img_path in image_paths:\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            img = transform(img)  # ‰Ω†ÂèØ‰ª•Áî®ÈÄÇÂΩìÁöÑ transform\n",
    "            img_np = np.array(img).astype(np.float32) / 255.0\n",
    "            pixel_means.append(img_np.mean())\n",
    "            pixel_stds.append(img_np.std())\n",
    "\n",
    "        patient_mean = np.mean(pixel_means)\n",
    "        patient_std = np.mean(pixel_stds)\n",
    "        body_part = study_rel_path.split(\"/\")[2]\n",
    "\n",
    "        stats.append({\n",
    "            \"path\": study_rel_path,  # Âä†ÂÖ• path\n",
    "            \"body_part\": body_part,\n",
    "            \"label\": label,\n",
    "            \"mean\": patient_mean,\n",
    "            \"std\": patient_std,\n",
    "            \"mode\": mode\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "582b9c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13457/13457 [02:00<00:00, 111.86it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1199/1199 [00:10<00:00, 116.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                path    body_part  label  \\\n",
      "0  MURA-v1.1/train/XR_SHOULDER/patient00001/study...  XR_SHOULDER      1   \n",
      "1  MURA-v1.1/train/XR_SHOULDER/patient00002/study...  XR_SHOULDER      1   \n",
      "2  MURA-v1.1/train/XR_SHOULDER/patient00003/study...  XR_SHOULDER      1   \n",
      "3  MURA-v1.1/train/XR_SHOULDER/patient00004/study...  XR_SHOULDER      1   \n",
      "4  MURA-v1.1/train/XR_SHOULDER/patient00005/study...  XR_SHOULDER      1   \n",
      "\n",
      "       mean       std   mode  \n",
      "0  0.289677  0.138886  train  \n",
      "1  0.172353  0.117897  train  \n",
      "2  0.246644  0.115778  train  \n",
      "3  0.287982  0.133889  train  \n",
      "4  0.178952  0.121661  train  \n",
      "(14656, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ëé∑ÂèñËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÁöÑÁóÖ‰∫∫ÁªüËÆ°‰ø°ÊÅØ\n",
    "train_stats = get_patient_stats(train_csv_path, \"train\")\n",
    "valid_stats = get_patient_stats(valid_csv_path, \"valid\")\n",
    "\n",
    "# ÂêàÂπ∂ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜÁöÑÁªüËÆ°‰ø°ÊÅØ\n",
    "df = pd.concat([train_stats, valid_stats], ignore_index=True)\n",
    "print(df.head())\n",
    "print(df.shape)  # Ê£ÄÊü•Êï∞ÊçÆÈõÜÂ§ßÂ∞è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e18ca2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËÆ≠ÁªÉÈõÜÂàÜÂ∏ÉÔºö\n",
      "label\n",
      "0    7462\n",
      "1    4269\n",
      "Name: count, dtype: int64\n",
      "\n",
      "È™åËØÅÈõÜÂàÜÂ∏ÉÔºö\n",
      "label\n",
      "0    1479\n",
      "1    1446\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Ê≠•È™§ 1ÔºöÂàÜÂ±ÇÊäΩÊ†∑‰∏é KMeans + PCA ËÅöÁ±ª\n",
    "stratified = df.groupby('body_part')\n",
    "\n",
    "df_train_new = []\n",
    "df_valid_new = []\n",
    "\n",
    "# ÂÖà‰æù body_part ÂàÜÂ±§\n",
    "for body_part, body_group in df.groupby('body_part'):\n",
    "    label_counts = body_group['label'].value_counts(normalize=True)\n",
    "    label_ratio_0 = label_counts.get(0, 0)\n",
    "    label_ratio_1 = label_counts.get(1, 0)\n",
    "\n",
    "    # Ê†πÊçÆÂéüÂßãÊØî‰æãËÆ°ÁÆóÈ™åËØÅÈõÜÁöÑÁõÆÊ†áÂ§ßÂ∞è\n",
    "    total_samples = len(body_group)\n",
    "    valid_size = int(total_samples * 0.2)  # È™åËØÅÈõÜÂ§ßÂ∞è‰∏∫ 20%\n",
    "\n",
    "    # ËÆ°ÁÆóÈ™åËØÅÈõÜÊ†áÁ≠æ 0 ÂíåÊ†áÁ≠æ 1 ÁöÑÁõÆÊ†áÊ†∑Êú¨Êï∞\n",
    "    valid_size_0 = int(valid_size * (label_ratio_0))\n",
    "    valid_size_1 = valid_size - valid_size_0  # Ââ©‰ΩôÁöÑÈ™åËØÅÈõÜÂ§ßÂ∞è‰Ωú‰∏∫Ê†áÁ≠æ 1 ÁöÑÊ†∑Êú¨Êï∞\n",
    "\n",
    "    # ËÆ°ÁÆóÊØè‰∏™Ê†áÁ≠æÁöÑÊñ∞ÂÄçÁéá\n",
    "    new_ratio_0 = (valid_size / 2) / valid_size_0  # Ë∞ÉÊï¥ÂêéÂÄçÁéáÔºåÁ°Æ‰øùÊ†áÁ≠æ 0 ÂíåÊ†áÁ≠æ 1 Êï∞ÈáèÂπ≥Ë°°\n",
    "    new_ratio_1 = (valid_size / 2) / valid_size_1  # Ë∞ÉÊï¥ÂêéÂÄçÁéáÔºåÁ°Æ‰øùÊ†áÁ≠æ 0 ÂíåÊ†áÁ≠æ 1 Êï∞ÈáèÂπ≥Ë°°\n",
    "\n",
    "    # ÂºïÂÖ•ÈöèÊú∫ÊÄßÔºåËåÉÂõ¥ ¬±0.03\n",
    "    random_factor = np.random.uniform(-0.05, 0.05)\n",
    "\n",
    "    # Ë∞ÉÊï¥ÂÄçÁéáÔºåÁ°Æ‰øù‰∏§ËÄÖÊÄªÂíå‰∏çÂèò\n",
    "    adjusted_ratio_0 = new_ratio_0 + random_factor\n",
    "    adjusted_ratio_1 = new_ratio_1 - random_factor\n",
    "\n",
    "    # ËÆ°ÁÆóÂÆûÈôÖÊäΩÊ†∑Êï∞Èáè\n",
    "    label_group_0 = body_group[body_group['label'] == 0]\n",
    "    label_group_1 = body_group[body_group['label'] == 1]\n",
    "\n",
    "    # Ê†πÊçÆË∞ÉÊï¥ÂêéÁöÑÂÄçÁéáËÆ°ÁÆóÊØè‰∏™Ê†áÁ≠æÁöÑÊäΩÊ†∑Êï∞Èáè\n",
    "    label_group_valid_0 = label_group_0.sample(n=int(valid_size_0 * adjusted_ratio_0), random_state=42)\n",
    "    label_group_valid_1 = label_group_1.sample(n=int(valid_size_1 * adjusted_ratio_1), random_state=42)\n",
    "\n",
    "    # Ââ©‰ΩôÊ†∑Êú¨‰Ωú‰∏∫ËÆ≠ÁªÉÈõÜ\n",
    "    label_group_train_0 = label_group_0.drop(label_group_valid_0.index)\n",
    "    label_group_train_1 = label_group_1.drop(label_group_valid_1.index)\n",
    "\n",
    "    # ÂêàÂπ∂ËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ\n",
    "    df_train_new.append(label_group_train_0)\n",
    "    df_train_new.append(label_group_train_1)\n",
    "    df_valid_new.append(label_group_valid_0)\n",
    "    df_valid_new.append(label_group_valid_1)\n",
    "\n",
    "# ÂêàÂπ∂ÊúÄÁªàÁöÑËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ\n",
    "df_train_final = pd.concat(df_train_new, ignore_index=True)\n",
    "df_valid_final = pd.concat(df_valid_new, ignore_index=True)\n",
    "\n",
    "# Á°Æ‰øùÊØèË°åÂè™ÊúâË∑ØÂæÑÂíåÊ†áÁ≠æ\n",
    "df_train_final_c = df_train_final[['path', 'label']]\n",
    "df_valid_final_c = df_valid_final[['path', 'label']]\n",
    "\n",
    "# ËæìÂá∫ÊúÄÁªàÁöÑËÆ≠ÁªÉÈõÜÂíåÈ™åËØÅÈõÜ\n",
    "df_train_final_c.to_csv('train_cluster_split.csv', index=False, header=False)\n",
    "df_valid_final_c.to_csv('valid_cluster_split.csv', index=False, header=False)\n",
    "\n",
    "# ÂèØÈÄâÔºöÁîüÊàêÊï∞ÊçÆÂàÜÂ∏ÉÊä•Âëä\n",
    "print(\"ËÆ≠ÁªÉÈõÜÂàÜÂ∏ÉÔºö\")\n",
    "print(df_train_final_c['label'].value_counts())\n",
    "print(\"\\nÈ™åËØÅÈõÜÂàÜÂ∏ÉÔºö\")\n",
    "print(df_valid_final_c['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b75815bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Train Data Distribution:\n",
      "label           0     1\n",
      "body_part              \n",
      "XR_ELBOW      989   540\n",
      "XR_FINGER    1163   526\n",
      "XR_FOREARM    562   248\n",
      "XR_HAND      1391   365\n",
      "XR_HUMERUS    321   263\n",
      "XR_SHOULDER  1154  1259\n",
      "XR_WRIST     1882  1068\n",
      "----------------------------------------\n",
      "\n",
      "üìä Valid Data Distribution:\n",
      "label          0    1\n",
      "body_part            \n",
      "XR_ELBOW     197  186\n",
      "XR_FINGER    209  212\n",
      "XR_FOREARM    97  103\n",
      "XR_HAND      207  222\n",
      "XR_HUMERUS    68   75\n",
      "XR_SHOULDER  309  293\n",
      "XR_WRIST     392  355\n",
      "----------------------------------------\n",
      "shape of train: (11731, 6)\n",
      "shape of valid: (2925, 6)\n",
      "‚úÖ Done! New train/valid csv saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ÊâìÂç∞ÂàÜÂ∏ÉÊä•Âëä\n",
    "def show_distribution(df_new, name):\n",
    "    dist = df_new.groupby([\"body_part\", \"label\"]).size().unstack(fill_value=0)\n",
    "    print(f\"\\nüìä {name} Data Distribution:\")\n",
    "    print(dist)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "show_distribution(df_train_final, \"Train\")\n",
    "show_distribution(df_valid_final, \"Valid\")\n",
    "print(\"shape of train:\", df_train_final.shape)\n",
    "print(\"shape of valid:\", df_valid_final.shape)\n",
    "print(\"‚úÖ Done! New train/valid csv saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntuml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
