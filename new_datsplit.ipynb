{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea4ed23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83274d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "train_csv_path = r\"C:\\Users\\Vivo\\2025_medicalimage_and_AI\\MURA-v1.1\\train_labeled_studies.csv\"\n",
    "valid_csv_path = r\"C:\\Users\\Vivo\\2025_medicalimage_and_AI\\MURA-v1.1\\valid_labeled_studies.csv\"\n",
    "data_root = r\"C:\\Users\\Vivo\\2025_medicalimage_and_AI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76bf6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1)\n",
    "])\n",
    "\n",
    "# 获取病人统计信息的函数\n",
    "def get_patient_stats(csv_path, mode):\n",
    "    df = pd.read_csv(csv_path, header=None, names=['path', 'label'])\n",
    "    stats = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        study_rel_path, label = row['path'], row['label']\n",
    "        study_path = os.path.join(data_root, study_rel_path)\n",
    "        image_paths = glob(os.path.join(study_path, \"*.png\"))\n",
    "\n",
    "        pixel_means = []\n",
    "        pixel_stds = []\n",
    "\n",
    "        for img_path in image_paths:\n",
    "            img = Image.open(img_path).convert(\"L\")\n",
    "            img = transform(img)  # 你可以用适当的 transform\n",
    "            img_np = np.array(img).astype(np.float32) / 255.0\n",
    "            pixel_means.append(img_np.mean())\n",
    "            pixel_stds.append(img_np.std())\n",
    "\n",
    "        patient_mean = np.mean(pixel_means)\n",
    "        patient_std = np.mean(pixel_stds)\n",
    "        body_part = study_rel_path.split(\"/\")[2]\n",
    "\n",
    "        stats.append({\n",
    "            \"path\": study_rel_path,  # 加入 path\n",
    "            \"body_part\": body_part,\n",
    "            \"label\": label,\n",
    "            \"mean\": patient_mean,\n",
    "            \"std\": patient_std,\n",
    "            \"mode\": mode\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "582b9c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13457 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13457/13457 [05:43<00:00, 39.19it/s]\n",
      "100%|██████████| 1199/1199 [00:11<00:00, 104.87it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 获取训练集和验证集的病人统计信息\n",
    "train_stats = get_patient_stats(train_csv_path, \"train\")\n",
    "valid_stats = get_patient_stats(valid_csv_path, \"valid\")\n",
    "\n",
    "# 合并训练集和验证集的统计信息\n",
    "#df = pd.concat([train_stats, valid_stats], ignore_index=True)\n",
    "#print(df.head())\n",
    "#print(df.shape)  # 检查数据集大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e18ca2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新的訓練集分布：\n",
      "label\n",
      "0    7479\n",
      "1    4252\n",
      "Name: count, dtype: int64\n",
      "\n",
      "验证集分布：\n",
      "label\n",
      "1    1463\n",
      "0    1462\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Household 驗證集分布：\n",
      "label\n",
      "0    943\n",
      "1    524\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 步骤 1：分层抽样与 KMeans + PCA 聚类\n",
    "stratified = df.groupby('body_part')\n",
    "\n",
    "df_train_new = []\n",
    "df_valid_new = []\n",
    "\n",
    "# 先依 body_part 分層\n",
    "for body_part, body_group in df.groupby('body_part'):\n",
    "    label_counts = body_group['label'].value_counts(normalize=True)\n",
    "    label_ratio_0 = label_counts.get(0, 0)\n",
    "    label_ratio_1 = label_counts.get(1, 0)\n",
    "\n",
    "    # 根据原始比例计算验证集的目标大小\n",
    "    total_samples = len(body_group)\n",
    "    valid_size = int(total_samples * 0.2)  # 验证集大小为 20%\n",
    "\n",
    "    # 计算验证集标签 0 和标签 1 的目标样本数\n",
    "    valid_size_0 = int(valid_size * (label_ratio_0))\n",
    "    valid_size_1 = valid_size - valid_size_0  # 剩余的验证集大小作为标签 1 的样本数\n",
    "\n",
    "    # 计算每个标签的新倍率\n",
    "    new_ratio_0 = (valid_size / 2) / valid_size_0  # 调整后倍率，确保标签 0 和标签 1 数量平衡\n",
    "    new_ratio_1 = (valid_size / 2) / valid_size_1  # 调整后倍率，确保标签 0 和标签 1 数量平衡\n",
    "\n",
    "    # 引入随机性，范围 ±0.03\n",
    "    random_factor = np.random.uniform(-0.03, 0.03)\n",
    "\n",
    "    # 调整倍率，确保两者总和不变\n",
    "    adjusted_ratio_0 = new_ratio_0 + random_factor\n",
    "    adjusted_ratio_1 = new_ratio_1 - random_factor\n",
    "\n",
    "    # 计算实际抽样数量\n",
    "    label_group_0 = body_group[body_group['label'] == 0]\n",
    "    label_group_1 = body_group[body_group['label'] == 1]\n",
    "\n",
    "    # 根据调整后的倍率计算每个标签的抽样数量\n",
    "    label_group_valid_0 = label_group_0.sample(n=int(valid_size_0 * adjusted_ratio_0), random_state=42)\n",
    "    label_group_valid_1 = label_group_1.sample(n=int(valid_size_1 * adjusted_ratio_1), random_state=42)\n",
    "\n",
    "    # 剩余样本作为训练集\n",
    "    label_group_train_0 = label_group_0.drop(label_group_valid_0.index)\n",
    "    label_group_train_1 = label_group_1.drop(label_group_valid_1.index)\n",
    "\n",
    "    # 合并训练集和验证集\n",
    "    df_train_new.append(label_group_train_0)\n",
    "    df_train_new.append(label_group_train_1)\n",
    "    df_valid_new.append(label_group_valid_0)\n",
    "    df_valid_new.append(label_group_valid_1)\n",
    "\n",
    "# 合并最终的训练集和验证集\n",
    "df_train_final = pd.concat(df_train_new, ignore_index=True)\n",
    "df_valid_final = pd.concat(df_valid_new, ignore_index=True)\n",
    "\n",
    "# 确保每行只有路径和标签\n",
    "df_train_final_c = df_train_final[['path', 'label']]\n",
    "df_valid_final_c = df_valid_final[['path', 'label']]\n",
    "\n",
    "df_valid_final_c.to_csv('valid_cluster_split.csv', index=False, header=False)\n",
    "\n",
    "'''加上household'''\n",
    "# 加入 body_part 資訊（因為之前輸出的是 path 和 label，所以先從原始 df 中補上）\n",
    "df_train_full = pd.merge(df_train_final_c, df[['path', 'body_part']], on='path', how='left')\n",
    "\n",
    "# 初始化新的 train 和 household list\n",
    "df_train_reduced = []\n",
    "df_household_valid = []\n",
    "\n",
    "# 依 body_part 分層抽出 1/8 作為 household valid\n",
    "for body_part, group in df_train_full.groupby('body_part'):\n",
    "    household_sample = group.sample(frac=1/8, random_state=42)\n",
    "    remaining = group.drop(household_sample.index)\n",
    "\n",
    "    df_household_valid.append(household_sample)\n",
    "    df_train_reduced.append(remaining)\n",
    "\n",
    "# 合併資料\n",
    "df_train_final_reduce = pd.concat(df_train_reduced, ignore_index=True)\n",
    "df_train_final_c_reduce = df_train_final_reduce[['path', 'label']]\n",
    "df_household_final = pd.concat(df_household_valid, ignore_index=True)\n",
    "df_household_final_c = df_household_final[['path', 'label']]\n",
    "\n",
    "# 輸出為 CSV\n",
    "df_train_final_c.to_csv('train_cluster_split.csv', index=False, header=False)\n",
    "df_household_final_c.to_csv('household_valid.csv', index=False, header=False)\n",
    "\n",
    "# 顯示分佈\n",
    "print(\"新的訓練集分布：\")\n",
    "print(df_train_final_c['label'].value_counts())\n",
    "\n",
    "print(\"\\n验证集分布：\")\n",
    "print(df_valid_final_c['label'].value_counts())\n",
    "\n",
    "print(\"\\nHousehold 驗證集分布：\")\n",
    "print(df_household_final_c['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b75815bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Data Distribution:\n",
      "label           0     1\n",
      "body_part              \n",
      "XR_ELBOW      881   459\n",
      "XR_FINGER    1009   469\n",
      "XR_FOREARM    491   218\n",
      "XR_HAND      1196   331\n",
      "XR_HUMERUS    275   235\n",
      "XR_SHOULDER  1020  1091\n",
      "XR_WRIST     1664   925\n",
      "----------------------------------------\n",
      "\n",
      "📊 Valid Data Distribution:\n",
      "label          0    1\n",
      "body_part            \n",
      "XR_ELBOW     187  193\n",
      "XR_FINGER    211  210\n",
      "XR_FOREARM    98  102\n",
      "XR_HAND      225  215\n",
      "XR_HUMERUS    71   73\n",
      "XR_SHOULDER  301  301\n",
      "XR_WRIST     369  369\n",
      "----------------------------------------\n",
      "\n",
      "📊 Household Valid Data Distribution:\n",
      "label          0    1\n",
      "body_part            \n",
      "XR_ELBOW     118   74\n",
      "XR_FINGER    152   59\n",
      "XR_FOREARM    70   31\n",
      "XR_HAND      177   41\n",
      "XR_HUMERUS    43   30\n",
      "XR_SHOULDER  142  160\n",
      "XR_WRIST     241  129\n",
      "----------------------------------------\n",
      "shape of train: (10264, 3)\n",
      "shape of valid: (2925, 6)\n",
      "shape of household valid: (1467, 3)\n",
      "✅ Done! New train/valid csv saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 打印分布报告\n",
    "def show_distribution(df_new, name):\n",
    "    dist = df_new.groupby([\"body_part\", \"label\"]).size().unstack(fill_value=0)\n",
    "    print(f\"\\n📊 {name} Data Distribution:\")\n",
    "    print(dist)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "show_distribution(df_train_final_reduce, \"Train\")\n",
    "show_distribution(df_valid_final, \"Valid\")\n",
    "show_distribution(df_household_final, \"Household Valid\")\n",
    "# 输出最终的 train 和 valid 数据集\n",
    "\n",
    "print(\"shape of train:\", df_train_final_reduce.shape)\n",
    "print(\"shape of valid:\", df_valid_final.shape)\n",
    "print(\"shape of household valid:\", df_household_final.shape)\n",
    "print(\"✅ Done! New train/valid csv saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2570f1ca",
   "metadata": {},
   "source": [
    "## 不使用kmeans_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd33bdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新的訓練集分布：\n",
      "label\n",
      "0    6535\n",
      "1    3734\n",
      "Name: count, dtype: int64\n",
      "\n",
      "验证集分布（已平衡）：\n",
      "label\n",
      "0    1483\n",
      "1    1441\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Household 驗證集分布（無需平衡）：\n",
      "label\n",
      "0    923\n",
      "1    540\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_train_new = []\n",
    "df_valid_new = []\n",
    "\n",
    "# 分 stratified valid：每個 body_part 各自處理\n",
    "for body_part, body_group in df.groupby('body_part'):\n",
    "    # 各類別分開\n",
    "    label_0 = body_group[body_group['label'] == 0]\n",
    "    label_1 = body_group[body_group['label'] == 1]\n",
    "\n",
    "    # 計算每類別該抽多少樣本（正負類各 10%，總共 valid 佔 20%）\n",
    "    # 隨機性範圍 ±0.03\n",
    "    random_factor = np.random.uniform(-0.03, 0.03)\n",
    "    valid_size_class_0 = int(len(body_group) *(0.1 + random_factor))\n",
    "    valid_size_class_1 = int(len(body_group) *(0.1 - random_factor))\n",
    "\n",
    "    # 若數量不足，使用 min 防止錯誤\n",
    "    sample_0 = label_0.sample(n=min(valid_size_class_0, len(label_0)), random_state=42)\n",
    "    sample_1 = label_1.sample(n=min(valid_size_class_1, len(label_1)), random_state=42)\n",
    "\n",
    "    # 合併成 valid\n",
    "    valid_part = pd.concat([sample_0, sample_1])\n",
    "    train_part = body_group.drop(valid_part.index)\n",
    "\n",
    "    df_valid_new.append(valid_part)\n",
    "    df_train_new.append(train_part)\n",
    "\n",
    "# 合併所有 body_part 的 train 和 valid\n",
    "df_train_final = pd.concat(df_train_new, ignore_index=True)\n",
    "df_valid_final = pd.concat(df_valid_new, ignore_index=True)\n",
    "\n",
    "# 保留 path 和 label 欄\n",
    "df_train_final_c = df_train_final[['path', 'label']]\n",
    "df_valid_final_c = df_valid_final[['path', 'label']]\n",
    "df_valid_final_c.to_csv('valid_balanced_random.csv', index=False, header=False)\n",
    "\n",
    "# household：從 train_final 中取每個 body_part 的 10%（無需平衡）\n",
    "df_train_full = pd.merge(df_train_final_c, df[['path', 'body_part']], on='path', how='left')\n",
    "\n",
    "df_train_reduced = []\n",
    "df_household_valid = []\n",
    "\n",
    "for body_part, group in df_train_full.groupby('body_part'):\n",
    "    n_household = int(len(group) / 8)  # 明確表示是取1/8\n",
    "    household_sample = group.sample(n=n_household, random_state=42)\n",
    "    remaining = group.drop(household_sample.index)\n",
    "\n",
    "    df_household_valid.append(household_sample)\n",
    "    df_train_reduced.append(remaining)\n",
    "\n",
    "# 合併\n",
    "df_train_final_reduce = pd.concat(df_train_reduced, ignore_index=True)\n",
    "df_train_final_c_reduce = df_train_final_reduce[['path', 'label']]\n",
    "df_household_final = pd.concat(df_household_valid, ignore_index=True)\n",
    "df_household_final_c = df_household_final[['path', 'label']]\n",
    "\n",
    "# 輸出 CSV\n",
    "df_train_final_c_reduce.to_csv('train_random_split.csv', index=False, header=False)\n",
    "df_household_final_c.to_csv('household_random.csv', index=False, header=False)\n",
    "\n",
    "# 顯示分布\n",
    "print(\"新的訓練集分布：\")\n",
    "print(df_train_final_c_reduce['label'].value_counts())\n",
    "\n",
    "print(\"\\n验证集分布（已平衡）：\")\n",
    "print(df_valid_final_c['label'].value_counts())\n",
    "\n",
    "print(\"\\nHousehold 驗證集分布（無需平衡）：\")\n",
    "print(df_household_final_c['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e19960c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Train Data Distribution:\n",
      "label           0     1\n",
      "body_part              \n",
      "XR_ELBOW      859   481\n",
      "XR_FINGER    1026   452\n",
      "XR_FOREARM    499   209\n",
      "XR_HAND      1185   346\n",
      "XR_HUMERUS    280   231\n",
      "XR_SHOULDER  1078  1034\n",
      "XR_WRIST     1608   981\n",
      "----------------------------------------\n",
      "\n",
      "📊 Valid Data Distribution:\n",
      "label          0    1\n",
      "body_part            \n",
      "XR_ELBOW     200  181\n",
      "XR_FINGER    203  218\n",
      "XR_FOREARM    82  119\n",
      "XR_HAND      243  193\n",
      "XR_HUMERUS    73   71\n",
      "XR_SHOULDER  230  372\n",
      "XR_WRIST     452  287\n",
      "----------------------------------------\n",
      "\n",
      "📊 Household Valid Data Distribution:\n",
      "label          0    1\n",
      "body_part            \n",
      "XR_ELBOW     127   64\n",
      "XR_FINGER    143   68\n",
      "XR_FOREARM    78   23\n",
      "XR_HAND      170   48\n",
      "XR_HUMERUS    36   36\n",
      "XR_SHOULDER  155  146\n",
      "XR_WRIST     214  155\n",
      "----------------------------------------\n",
      "shape of train: (10269, 3)\n",
      "shape of valid: (2924, 6)\n",
      "shape of household valid: (1463, 3)\n",
      "✅ Done! New train/valid csv saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 打印分布报告\n",
    "def show_distribution(df_new, name):\n",
    "    dist = df_new.groupby([\"body_part\", \"label\"]).size().unstack(fill_value=0)\n",
    "    print(f\"\\n📊 {name} Data Distribution:\")\n",
    "    print(dist)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "show_distribution(df_train_final_reduce, \"Train\")\n",
    "show_distribution(df_valid_final, \"Valid\")\n",
    "show_distribution(df_household_final, \"Household Valid\")\n",
    "# 输出最终的 train 和 valid 数据集\n",
    "\n",
    "print(\"shape of train:\", df_train_final_reduce.shape)\n",
    "print(\"shape of valid:\", df_valid_final.shape)\n",
    "print(\"shape of household valid:\", df_household_final.shape)\n",
    "print(\"✅ Done! New train/valid csv saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a62fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_stats shape: label\n",
      "0    8280\n",
      "1    5177\n",
      "Name: count, dtype: int64\n",
      "新的訓練集分布：\n",
      "label\n",
      "0    7463\n",
      "1    4648\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Household 驗證集分布（無需平衡）：\n",
      "label\n",
      "0    817\n",
      "1    529\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train_reduced = []\n",
    "df_household_valid = []\n",
    "print(\"train_stats shape:\", train_stats['label'].value_counts())\n",
    "for body_part, group in train_stats.groupby('body_part'):\n",
    "    household_sample = group.sample(frac=0.1, random_state=42)\n",
    "\n",
    "    remaining = group.drop(household_sample.index)\n",
    "\n",
    "    df_household_valid.append(household_sample)\n",
    "    df_train_reduced.append(remaining)\n",
    "\n",
    "# 合併\n",
    "df_train_final_reduce = pd.concat(df_train_reduced, ignore_index=True)\n",
    "df_train_final_c_reduce = df_train_final_reduce[['path', 'label']]\n",
    "df_household_final = pd.concat(df_household_valid, ignore_index=True)\n",
    "df_household_final_c = df_household_final[['path', 'label']]\n",
    "\n",
    "# 輸出 CSV\n",
    "df_train_final_c_reduce.to_csv('origin_train.csv', index=False, header=False)\n",
    "df_household_final_c.to_csv('household_for_real.csv', index=False, header=False)\n",
    "\n",
    "# 顯示分布\n",
    "print(\"新的訓練集分布：\")\n",
    "print(df_train_final_c_reduce['label'].value_counts())\n",
    "\n",
    "print(\"\\nHousehold 驗證集分布（無需平衡）：\")\n",
    "print(df_household_final_c['label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ntuml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
